{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of various Classification Models of Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data', header = None, prefix = 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0      f1      f2      f3      f4      f5      f6      f7      f8  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "5  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "6  0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
       "7  0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
       "8  0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
       "9  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
       "\n",
       "       f9 ...      f51     f52     f53     f54     f55     f56     f57  \\\n",
       "0  0.2111 ...   0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872 ...   0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194 ...   0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264 ...   0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459 ...   0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "5  0.3039 ...   0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "6  0.3513 ...   0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
       "7  0.2838 ...   0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n",
       "8  0.1487 ...   0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
       "9  0.0251 ...   0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
       "\n",
       "      f58     f59  f60  \n",
       "0  0.0090  0.0032    R  \n",
       "1  0.0052  0.0044    R  \n",
       "2  0.0095  0.0078    R  \n",
       "3  0.0040  0.0117    R  \n",
       "4  0.0107  0.0094    R  \n",
       "5  0.0051  0.0062    R  \n",
       "6  0.0036  0.0103    R  \n",
       "7  0.0048  0.0053    R  \n",
       "8  0.0059  0.0022    R  \n",
       "9  0.0056  0.0040    R  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f50</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               f0          f1          f2          f3          f4          f5  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               f6          f7          f8          f9     ...             f50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000     ...      208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259     ...        0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416     ...        0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300     ...        0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275     ...        0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400     ...        0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700     ...        0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600     ...        0.100400   \n",
       "\n",
       "              f51         f52         f53         f54         f55         f56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "              f57         f58         f59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating  the Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'f60':'Label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.get_dummies(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_M'] = df_cat['M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>Label</th>\n",
       "      <th>is_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0      f1      f2      f3      f4      f5      f6      f7      f8  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       f9  ...      f52     f53     f54     f55     f56     f57     f58  \\\n",
       "0  0.2111  ...   0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872  ...   0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194  ...   0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264  ...   0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459  ...   0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "      f59  Label  is_M  \n",
       "0  0.0032      R     0  \n",
       "1  0.0044      R     0  \n",
       "2  0.0078      R     0  \n",
       "3  0.0117      R     0  \n",
       "4  0.0094      R     0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>is_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label  is_M\n",
       "0     R     0\n",
       "1     R     0\n",
       "2     R     0\n",
       "3     R     0\n",
       "4     R     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Label == 'R'][['Label','is_M']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>is_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  is_M\n",
       "97      M     1\n",
       "98      M     1\n",
       "99      M     1\n",
       "100     M     1\n",
       "101     M     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Label == 'M'][['Label','is_M']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression on the Entire Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['is_M']\n",
    "X = df.iloc[ : , :60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual = y\n",
    "Predicted = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'Actual' : Actual, 'Predicted' : Predicted}\n",
    "Comp_DF = pd.DataFrame(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0       0          0\n",
       "1       0          1\n",
       "2       0          1\n",
       "3       0          1\n",
       "4       0          1\n",
       "5       0          0\n",
       "6       0          0\n",
       "7       0          1\n",
       "8       0          1\n",
       "9       0          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comp_DF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total No. of Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comp_DF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Correct Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comp_DF[Comp_DF.Actual == Comp_DF.Predicted].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.21153846153845"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Comp_DF[Comp_DF.Actual == Comp_DF.Predicted].shape[0]/Comp_DF.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. KNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a KNN (K = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_1 = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual = y\n",
    "Predicted = KNN_1.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b KNN (K=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_4 = KNeighborsClassifier(n_neighbors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_4.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual = y\n",
    "Predicted = KNN_4.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.90384615384616\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c KNN (K=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_5 = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_5.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual = y\n",
    "Predicted = KNN_4.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.90384615384616\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual = y\n",
    "Predicted = Tree.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Logistic Regression vs KNN(1,4 and 5) and Decision Tree we can conclude that KNN with K = 1 and Decision Tree gives us the best result with 100% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But our analysis has two major limitations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. We have trained and tested on the same data set. So the Accuracy observed is the training accuracy which is not a good parameter as it is not taking in to account for out of sample or unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. KNN = 1 will always search for one nearest neighbour belonging to the test data and since we've trained on the entire data set it is bound to give us accurate result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can reduce the above limitations by spliting the dataset into Training and Testing data sets. Train our model on the training data set and use Test set as new unseen data for predictions.\n",
    "\n",
    "## This process of evaluation is known as Test/Train Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logistic Regression with Test/Train split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "Actual = y_test\n",
    "Predicted = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.61538461538461\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even though we just see an increase of just 2% from our previous analysis of Logistic Regression but this accuracy is a better measure of actual predictions as it is made on unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. KNN with Test/Train Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.a KNN = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "KNN_1.fit(X_train,y_train)\n",
    "Actual = y_test\n",
    "Predicted = KNN_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.6923076923077\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.b KNN = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_4 = KNeighborsClassifier(n_neighbors=4)\n",
    "KNN_4.fit(X_train,y_train)\n",
    "Actual = y_test\n",
    "Predicted = KNN_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.76923076923077\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.c KNN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_5.fit(X_train,y_train)\n",
    "Actual = y_test\n",
    "Predicted = KNN_5.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.92307692307693\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Decision Tree Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = DecisionTreeClassifier(criterion='gini')\n",
    "Tree.fit(X_train,y_train)\n",
    "Actual = y_test\n",
    "Predicted = Tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.3076923076923\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Actual, Predicted)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Test/Train Split method now we have Logistic Regression as a better model as it accounts for Higher Test Accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split method gives us more reliable predictions but it still has it's share of disadvantages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Less accurate estimate of out of sample accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing accuracy can change a lot depending upon which observation happens to be on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can further tune our model using Cross Validation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Process is process where we have multiple clusters of test/train splits distributed across the entire data set giving maximum coverage as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Logistic Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "y = df['is_M']\n",
    "X = df.iloc[ : , :60]\n",
    "Accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31818182, 0.80952381, 0.76190476, 0.71428571, 0.66666667,\n",
       "       0.47619048, 0.76190476, 0.85      , 0.6       , 0.75      ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.08658008658008"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. KNN with Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8a. Cross Validation with K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "Accuracy = cross_val_score(KNN_1, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54545455, 0.80952381, 0.80952381, 0.47619048, 0.42857143,\n",
       "       0.52380952, 0.61904762, 0.7       , 0.45      , 0.75      ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.12121212121212"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8b. Cross Validation with K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_5 = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = cross_val_score(KNN_5, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.85714286, 0.80952381, 0.52380952, 0.66666667,\n",
       "       0.42857143, 0.66666667, 0.55      , 0.3       , 0.7       ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.023809523809526"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8c. Finding the best value of K using Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Range = list(range(1,30))\n",
    "l1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    Accuracy = cross_val_score(KNN, X, y, cv=10, scoring='accuracy').mean()*100\n",
    "    l1.append(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e03997c9e8>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e0399164a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Range, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the graph we can deduce that K = 17 gives highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.40909090909092"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_17 = KNeighborsClassifier(n_neighbors=17)\n",
    "Accuracy = cross_val_score(KNN_17, X, y, cv=10, scoring='accuracy')\n",
    "Accuracy.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Decision Tree with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = cross_val_score(Tree, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54545455, 0.66666667, 0.57142857, 0.42857143, 0.52380952,\n",
       "       0.76190476, 0.66666667, 0.65      , 0.7       , 0.75      ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.645021645021636"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comapring the three Classification Models we arrived at last that Logistic Regression with 67% accurcay edges out the KNN Method and Decision Tree which had highest accuracy for K = 17 with 64.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We compared three scenarios\n",
    "\n",
    "### 1. Traing Model with Entire Data Set\n",
    "### 2. Using Test/Train Split\n",
    "### 3. Cross Validation\n",
    "\n",
    "### Each following step is an improvement to its previous version. Why is the accuracy of a Cross Validated Model Lower than Test Train Split? But is Cross Validation the best possible method to reach closest to the maximum accuracy?\n",
    "\n",
    "### In real life scenarios we deal with a lot greater datasets. Our sample dataset is realtively too small for Cross Validation. Further, we did no feature engineering before training our model which could be another explanation for our low accuracy for the Cross Validated Model\n",
    "\n",
    "### The results observed from Cross Validation can further be improved. We have multiple trials of cross validation iterations. We can hold out portion of the data set as an unseen data set and do cross validation on the rest of the data etc.\n",
    "\n",
    "### Likewise we can improvise our results on decison tress as well by using ensemble methods and also by tuning its hyperparameters like depth, max_leaf etc.\n",
    "\n",
    "### But further improvisation may come at a cost of more complex calculations and more computational time. Depending upon particular problems we should take a call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
